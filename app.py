import streamlit as st
import requests
import json

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(
    page_title="Cerebras AI",
    page_icon="âš¡",
    layout="centered"
)

# ØªØ®ØµÙŠØµ CSS Ù„Ø¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
st.markdown("""
<style>
    .stChatMessage { direction: rtl; text-align: right; }
    .stTextInput > div > div > input { direction: rtl; text-align: right; }
    .stTextArea > div > div > textarea { direction: rtl; text-align: right; }
    p { direction: rtl; text-align: right; }
</style>
""", unsafe_allow_html=True)

st.title("âš¡ Cerebras: Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø®Ø§Ø±Ù‚")

# --- 2. Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Secrets (Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø°ÙƒÙŠØ©) ---
try:
    # ÙŠØ­Ø§ÙˆÙ„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Ø£Ø³Ø±Ø§Ø± Streamlit
    api_key = st.secrets["CEREBRAS_API_KEY"]
    st.sidebar.success("âœ… Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ØªØµÙ„ Ø¨Ø£Ù…Ø§Ù† (Secrets)")
except (FileNotFoundError, KeyError):
    # ÙÙŠ Ø­Ø§Ù„ ÙƒÙ†Øª ØªØ¬Ø±Ø¨ Ù…Ø­Ù„ÙŠØ§Ù‹ ÙˆÙ„Ù… ØªØ¶Ø¨Ø· Ø§Ù„Ø£Ø³Ø±Ø§Ø±ØŒ ÙŠØ·Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ ÙŠØ¯ÙˆÙŠØ§Ù‹
    st.sidebar.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙØªØ§Ø­ ÙÙŠ Secrets")
    api_key = st.sidebar.text_input("Ø£Ø¯Ø®Ù„ Ø§Ù„Ù…ÙØªØ§Ø­ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù„Ù„ØªØ¬Ø±Ø¨Ø©:", type="password")

# Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙˆÙØ± Ø§Ù„Ù…ÙØªØ§Ø­ Ø¨Ø£ÙŠ Ø·Ø±ÙŠÙ‚Ø©ØŒ Ù†ÙˆÙ‚Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if not api_key:
    st.info("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¹Ø¯Ø§Ø¯ CEREBRAS_API_KEY ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Streamlit Cloud.")
    st.stop()

# --- 3. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
with st.sidebar:
    st.markdown("---")
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    model = st.selectbox(
        "ğŸ§  Ø§Ø®ØªØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„:",
        ["llama-3.3-70b", "llama3.1-8b", "qwen-3-32b"],
        index=0
    )
    
    # Ø´Ø®ØµÙŠØ© Ø§Ù„Ø¨ÙˆØª
    system_prompt = st.text_area(
        "ğŸ­ Ø¯ÙˆØ± Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:",
        value="Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ÙÙŠØ¯ØŒ ØªØªØ­Ø¯Ø« Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø© ÙˆÙˆØ¶ÙˆØ­.",
        height=100
    )
    
    # Ø²Ø± Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    if st.button("ğŸ—‘ï¸ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- 4. Ø¯Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ (Streaming Engine) ---
def stream_cerebras_api(messages, api_key, model, system_prompt):
    url = "https://api.cerebras.ai/v1/chat/completions"
    
    # Ø¯Ù…Ø¬ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
    full_messages = [{"role": "system", "content": system_prompt}] + messages
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model,
        "messages": full_messages,
        "temperature": 0.7,
        "max_tokens": 1500,
        "stream": True 
    }
    
    try:
        with requests.post(url, headers=headers, json=data, stream=True) as response:
            if response.status_code != 200:
                yield f"âš ï¸ Ø®Ø·Ø£: {response.text}"
                return

            for line in response.iter_lines():
                if line:
                    decoded_line = line.decode('utf-8')
                    if decoded_line.startswith("data: "):
                        json_str = decoded_line[6:] 
                        if json_str.strip() == "[DONE]":
                            break
                        try:
                            chunk = json.loads(json_str)
                            content = chunk['choices'][0]['delta'].get('content', '')
                            if content:
                                yield content
                        except:
                            continue
    except Exception as e:
        yield f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}"

# --- 5. Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ---

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
if prompt := st.chat_input("Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡..."):
    
    # Ø¹Ø±Ø¶ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ø¹Ø±Ø¶ Ø§Ù„Ø¬ÙˆØ§Ø¨
    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        
        # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø¯Ø§Ù„Ø©
        for chunk in stream_cerebras_api(st.session_state.messages, api_key, model, system_prompt):
            full_response += chunk
            response_placeholder.markdown(full_response + "â–Œ")
        
        response_placeholder.markdown(full_response)
    
    # Ø­ÙØ¸ Ø§Ù„Ø¬ÙˆØ§Ø¨
    st.session_state.messages.append({"role": "assistant", "content": full_response})
