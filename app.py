import streamlit as st
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_TABLE_DIRECTION
from cerebras.cloud.sdk import Cerebras
import pandas as pd
import json
import io
import time

# ---------------------------------------------------------
# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ÙˆØªØµÙ…ÙŠÙ…Ù‡Ø§ (CSS Ø¹Ø±Ø¨ÙŠ ÙˆØ¹ØµØ±ÙŠ)
# ---------------------------------------------------------
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØªØ±Ø¨ÙˆÙŠ Ø§Ù„Ø´Ø§Ù…Ù„",
    page_icon="ğŸ“š",
    layout="wide"
)

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Tajawal:wght@400;500;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Tajawal', sans-serif;
        direction: rtl;
        text-align: right;
    }
    
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† */
    h1, h2, h3 { color: #154360; font-weight: 800; }
    
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª */
    .stTabs [data-baseweb="tab-list"] { gap: 10px; }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #F0F3F4;
        border-radius: 5px 5px 0 0;
        color: #154360;
        font-weight: bold;
    }
    .stTabs [aria-selected="true"] {
        background-color: #154360;
        color: white;
    }

    /* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton>button {
        background-color: #154360;
        color: white;
        border-radius: 8px;
        font-weight: bold;
        transition: 0.3s;
    }
    .stButton>button:hover { background-color: #1A5276; }
    
    /* Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ */
    [data-testid="stDataFrame"] { direction: rtl; }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# 2. Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ (Ø§Ù„Ø«Ø§Ø¨ØªØ©)
# ---------------------------------------------------------
WEEKLY_SCHEDULE = {
    "Ø§Ù„Ø£Ø­Ø¯": [
        {"time": "08:00 - 09:45", "activity": "ØªØ¹Ø¨ÙŠØ± Ø´ÙÙˆÙŠ"},
        {"time": "08:00 - 09:45", "activity": "Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©"},
        {"time": "08:00 - 09:45", "activity": "Ø±ÙŠØ§Ø¶ÙŠØ§Øª"},
        {"time": "10:00 - 11:15", "activity": "Øª Ø¹Ù„Ù…ÙŠØ©"},
        {"time": "10:00 - 11:15", "activity": "Øª Ø¥Ø³Ù„Ø§Ù…ÙŠØ©"},
        {"time": "13:00 - 15:00", "activity": "Ù…Ø³Ø±Ø­ ÙˆØ¹Ø±Ø§Ø¦Ø³"},
        {"time": "13:00 - 15:00", "activity": "Ø±Ø³Ù… ÙˆØ£Ø´ØºØ§Ù„"},
        {"time": "13:00 - 15:00", "activity": "Øª Ø¨Ø¯Ù†ÙŠØ©"}
    ],
    "Ø§Ù„Ø§Ø«Ù†ÙŠÙ†": [
        {"time": "08:00 - 09:45", "activity": "Ø±ÙŠØ§Ø¶ÙŠØ§Øª"},
        {"time": "08:00 - 09:45", "activity": "ØªØ¹Ø¨ÙŠØ± Ø´ÙÙˆÙŠ"},
        {"time": "08:00 - 09:45", "activity": "ØªØ®Ø·ÙŠØ·"},
        {"time": "10:00 - 11:15", "activity": "Øª Ø¹Ù„Ù…ÙŠØ©"},
        {"time": "10:00 - 11:15", "activity": "Øª Ù…Ø¯Ù†ÙŠØ©"},
        {"time": "13:00 - 15:00", "activity": "Ù…Ø³Ø±Ø­ ÙˆØ¹Ø±Ø§Ø¦Ø³"},
        {"time": "13:00 - 15:00", "activity": "Ø±Ø³Ù… ÙˆØ£Ø´ØºØ§Ù„"},
        {"time": "13:00 - 15:00", "activity": "Øª Ø¨Ø¯Ù†ÙŠØ©"}
    ],
    "Ø§Ù„Ø«Ù„Ø§Ø«Ø§Ø¡": [
        {"time": "08:00 - 09:45", "activity": "ØªØ¹Ø¨ÙŠØ± Ø´ÙÙˆÙŠ"},
        {"time": "08:00 - 09:45", "activity": "Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©"},
        {"time": "08:00 - 09:45", "activity": "Ø±ÙŠØ§Ø¶ÙŠØ§Øª"},
        {"time": "10:00 - 11:15", "activity": "Øª Ø¥Ø³Ù„Ø§Ù…ÙŠØ©"},
        {"time": "10:00 - 11:15", "activity": "Øª Ø¨Ø¯Ù†ÙŠØ©"}
    ],
    "Ø§Ù„Ø£Ø±Ø¨Ø¹Ø§Ø¡": [
        {"time": "08:00 - 09:45", "activity": "Ø±ÙŠØ§Ø¶ÙŠØ§Øª"},
        {"time": "08:00 - 09:45", "activity": "Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©"},
        {"time": "08:00 - 09:45", "activity": "ØªØ®Ø·ÙŠØ·"},
        {"time": "10:00 - 11:15", "activity": "Øª Ø¹Ù„Ù…ÙŠØ©"},
        {"time": "10:00 - 11:15", "activity": "Øª Ù…Ø¯Ù†ÙŠØ©"},
        {"time": "13:00 - 15:00", "activity": "Øª Ø¥ÙŠÙ‚Ø§Ø¹ÙŠØ©"},
        {"time": "13:00 - 15:00", "activity": "Ù…ÙˆØ³ÙŠÙ‚Ù‰ ÙˆØ¥Ù†Ø´Ø§Ø¯"},
        {"time": "13:00 - 15:00", "activity": "Øª Ø¨Ø¯Ù†ÙŠØ©"}
    ],
    "Ø§Ù„Ø®Ù…ÙŠØ³": [
        {"time": "08:00 - 09:45", "activity": "Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©"},
        {"time": "08:00 - 09:45", "activity": "Ø±ÙŠØ§Ø¶ÙŠØ§Øª"},
        {"time": "08:00 - 09:45", "activity": "Øª Ø¹Ù„Ù…ÙŠØ©"},
        {"time": "10:00 - 11:15", "activity": "Øª Ø¥ÙŠÙ‚Ø§Ø¹ÙŠØ©"},
        {"time": "10:00 - 11:15", "activity": "Ù…ÙˆØ³ÙŠÙ‚Ù‰ ÙˆØ¥Ù†Ø´Ø§Ø¯"}
    ]
}

# ---------------------------------------------------------
# 3. Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© (Ø§Ø³ØªØ®Ø±Ø§Ø¬ØŒ ØªØ­Ù„ÙŠÙ„ØŒ Word)
# ---------------------------------------------------------

def get_domain(activity):
    """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¬Ø§Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø´Ø§Ø·"""
    act = activity.strip()
    if any(x in act for x in ["ØªØ¹Ø¨ÙŠØ±", "Ù‚Ø±Ø§Ø¡Ø©", "ØªØ®Ø·ÙŠØ·", "Ù„ØºØ©"]): return "Ø§Ù„Ù„ØºÙˆÙŠ"
    elif "Ø±ÙŠØ§Ø¶ÙŠØ§Øª" in act: return "Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ"
    elif any(x in act for x in ["Ø¹Ù„Ù…ÙŠØ©", "ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§"]): return "Ø§Ù„Ø¹Ù„Ù…ÙŠ"
    elif any(x in act for x in ["Ø¥Ø³Ù„Ø§Ù…ÙŠØ©", "Ù…Ø¯Ù†ÙŠØ©"]): return "Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ"
    elif any(x in act for x in ["Ù…Ø³Ø±Ø­", "Ø±Ø³Ù…", "Ù…ÙˆØ³ÙŠÙ‚Ù‰", "Ø¥Ù†Ø´Ø§Ø¯", "ØªØ´ÙƒÙŠÙ„ÙŠØ©"]): return "Ø§Ù„ÙÙ†ÙŠ"
    elif any(x in act for x in ["Ø¨Ø¯Ù†ÙŠØ©", "Ø¥ÙŠÙ‚Ø§Ø¹ÙŠØ©", "Ø±ÙŠØ§Ø¶Ø©"]): return "Ø§Ù„Ø¨Ø¯Ù†ÙŠ ÙˆØ§Ù„Ø¥ÙŠÙ‚Ø§Ø¹ÙŠ"
    return ""

def extract_text_from_docx(file):
    doc = Document(file)
    full_text = []
    for para in doc.paragraphs:
        if para.text.strip(): full_text.append(para.text)
    for table in doc.tables:
        for row in table.rows:
            row_text = [c.text.strip().replace("\n", " ") for c in row.cells if c.text.strip()]
            if row_text: full_text.append(" | ".join(row_text))
    return "\n".join(full_text)

def analyze_with_cerebras(text, key, model_id, mode="journal"):
    """
    mode='journal': Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ· Ù„Ù„Ù…Ø°ÙƒØ±Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© (Ù†Ø´Ø§Ø·ØŒ Ù…ÙˆØ¶ÙˆØ¹ØŒ ÙƒÙØ§Ø¡Ø©).
    mode='structure': Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ù…Ù‚Ø§Ø·Ø¹ (Ø§Ù„Ù…Ø¬Ø§Ù„ØŒ Ø§Ù„ÙˆØ­Ø¯Ø©ØŒ Ø¥Ù„Ø®).
    """
    client = Cerebras(api_key=key)
    
    if mode == "journal":
        prompt = """
        Ø§Ø³ØªØ®Ø±Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ø±ÙˆØ³ Ù„Ù…Ù„Ø¡ Ø¬Ø¯ÙˆÙ„ ÙŠÙˆÙ…ÙŠ.
        Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ JSON List Ù„Ù„ÙƒØ§Ø¦Ù†Ø§Øª:
        {"Ø§Ù„Ù†Ø´Ø§Ø·": "...", "Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹": "...", "Ø§Ù„ÙƒÙØ§Ø¡Ø©": "...", "Ø§Ù„Ù…Ø¤Ø´Ø±": "..."}
        Ø­Ø§ÙˆÙ„ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ù…Ø¹ (Ø±ÙŠØ§Ø¶ÙŠØ§ØªØŒ ØªØ¹Ø¨ÙŠØ± Ø´ÙÙˆÙŠØŒ Øª Ø¹Ù„Ù…ÙŠØ©ØŒ Ø¥Ù„Ø®).
        """
    else: # mode == structure
        prompt = """
        Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‡ÙŠÙƒÙ„Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø¯Ø±ÙˆØ³.
        Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ JSON List Ù„Ù„ÙƒØ§Ø¦Ù†Ø§Øª:
        1. "Ø§Ù„Ù…Ø¬Ø§Ù„_Ø£Ùˆ_Ø§Ù„Ù…Ù‚Ø·Ø¹": (Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙƒØ¨ÙŠØ±ØŒ Ù…Ø«Ù„: Ø§Ù„Ù…Ø¬Ø§Ù„ Ø§Ù„Ù„ØºÙˆÙŠØŒ Ø§Ù„ÙˆØ­Ø¯Ø© 3ØŒ Ø§Ù„Ø­ÙŠØ§Ø© Ø§Ù„Ù…Ø¯Ø±Ø³ÙŠØ©).
        2. "Ø§Ù„Ù†Ø´Ø§Ø·": Ù†ÙˆØ¹ Ø§Ù„Ø­ØµØ©.
        3. "Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹": Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¯Ø±Ø³.
        4. "Ø§Ù„ÙƒÙØ§Ø¡Ø©_Ø§Ù„Ø®ØªØ§Ù…ÙŠØ©": Ø§Ù„ÙƒÙØ§Ø¡Ø©.
        5. "Ø§Ù„Ù…Ø¤Ø´Ø±": Ø§Ù„Ù‡Ø¯Ù Ø§Ù„ØªØ¹Ù„Ù…ÙŠ.
        """

    try:
        completion = client.chat.completions.create(
            model=model_id,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": text[:28000]}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        return json.loads(completion.choices[0].message.content)
    except Exception as e:
        return {"error": str(e)}

def create_daily_journal_doc(day_name, extracted_lessons):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Word Ù„Ù„Ù…Ø°ÙƒØ±Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©"""
    doc = Document()
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© Landscape
    section = doc.sections[0]
    section.page_width = Inches(11.69)
    section.page_height = Inches(8.27)
    section.orientation = 1 
    section.left_margin = Inches(0.5)
    section.right_margin = Inches(0.5)
    
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
    p = doc.add_paragraph()
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = p.add_run(f'Ø§Ù„Ù…Ø°ÙƒØ±Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© - ÙŠÙˆÙ…: {day_name}')
    run.font.size = Pt(18)
    run.font.bold = True
    run.font.color.rgb = RGBColor(21, 67, 96) # Dark Blue

    # Ø§Ù„Ø¬Ø¯ÙˆÙ„
    headers = ["Ø§Ù„ØªÙˆÙ‚ÙŠØª", "Ø§Ù„Ù†Ø´Ø§Ø·", "Ø§Ù„Ù…Ø¬Ø§Ù„", "Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ (Ø§Ù„Ù…Ø­ØªÙˆÙ‰)", "Ø§Ù„ÙƒÙØ§Ø¡Ø©", "Ø§Ù„Ù…Ø¤Ø´Ø±", "Ù…Ù„Ø§Ø­Ø¸Ø§Øª"]
    table = doc.add_table(rows=1, cols=len(headers))
    table.style = 'Table Grid'
    table.direction = WD_TABLE_DIRECTION.RTL
    table.autofit = False 
    
    # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø£Ø³
    widths = [0.8, 1.0, 0.9, 1.5, 1.2, 1.2, 0.8]
    for i, header in enumerate(headers):
        cell = table.rows[0].cells[i]
        cell.text = header
        cell.width = Inches(widths[i])
        run = cell.paragraphs[0].runs[0]
        run.font.bold = True
        run.font.size = Pt(11)
        
    # ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    day_schedule = WEEKLY_SCHEDULE.get(day_name, [])
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    lessons_list = []
    if isinstance(extracted_lessons, dict):
        for val in extracted_lessons.values():
            if isinstance(val, list): lessons_list = val; break
        if not lessons_list: lessons_list = [extracted_lessons]
    else: lessons_list = extracted_lessons

    for slot in day_schedule:
        row = table.add_row()
        cells = row.cells
        
        # 1. Ø§Ù„ØªÙˆÙ‚ÙŠØª ÙˆØ§Ù„Ù†Ø´Ø§Ø· (Ø«Ø§Ø¨Øª)
        cells[0].text = slot['time']
        cells[1].text = slot['activity']
        
        # 2. Ø§Ù„Ù…Ø¬Ø§Ù„ (ØªÙ„Ù‚Ø§Ø¦ÙŠ)
        cells[2].text = get_domain(slot['activity'])
        
        # 3. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¯Ø±Ø³ (AI Data)
        found = None
        clean_slot = slot['activity'].replace("Øª ", "").replace("Ù…Ø¨Ø§Ø¯Ø¦ ", "").strip()
        for lesson in lessons_list:
            lesson_act = str(lesson.get('Ø§Ù„Ù†Ø´Ø§Ø·', '')).replace("Øª ", "").replace("Ù…Ø¨Ø§Ø¯Ø¦ ", "").strip()
            if clean_slot in lesson_act or lesson_act in clean_slot:
                found = lesson
                break
        
        if found:
            cells[3].text = str(found.get('Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹', ''))
            cells[4].text = str(found.get('Ø§Ù„ÙƒÙØ§Ø¡Ø©', '') or found.get('Ø§Ù„ÙƒÙØ§Ø¡Ø©_Ø§Ù„Ø®ØªØ§Ù…ÙŠØ©', ''))
            cells[5].text = str(found.get('Ø§Ù„Ù…Ø¤Ø´Ø±', ''))
        
        # ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø®Ù„Ø§ÙŠØ§
        for i, cell in enumerate(cells):
            cell.width = Inches(widths[i])
            for p in cell.paragraphs:
                p.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                if p.runs: p.runs[0].font.name = "Arial"

    return doc

# ---------------------------------------------------------
# 4. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# ---------------------------------------------------------
with st.sidebar:
    st.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    api_key = st.secrets.get("CEREBRAS_API_KEY") or st.text_input("Cerebras API Key", type="password")
    model_choice = st.selectbox("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", ["llama-3.3-70b", "llama3.1-8b"])
    st.info("ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ù… Llama 3.3 Ù„Ø£ÙØ¶Ù„ Ù†ØªØ§Ø¦Ø¬.")

st.title("ğŸ“š Ø§Ù„Ù…Ù†ØµØ© Ø§Ù„ØªØ±Ø¨ÙˆÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©")

# --- Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª ---
tab1, tab2 = st.tabs(["ğŸ“ Ø§Ù„Ù…Ø°ÙƒØ±Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ© (Ù…Ù„Ø¡ Ø§Ù„ØªÙˆÙ‚ÙŠØª)", "ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ø¬Ø¯ÙˆÙ„"])

# ==========================================
# Tab 1: Ø§Ù„Ù…Ø°ÙƒØ±Ø© Ø§Ù„ÙŠÙˆÙ…ÙŠØ©
# ==========================================
with tab1:
    st.header("Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø°ÙƒØ±Ø© ÙŠÙˆÙ…ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ")
    col1, col2 = st.columns([2, 1])
    
    with col1:
        file_tab1 = st.file_uploader("ğŸ“‚ Ù…Ù„Ù Ø§Ù„Ù…Ø°ÙƒØ±Ø§Øª (.docx)", type=["docx"], key="f1")
    with col2:
        day_selected = st.selectbox("ğŸ“… Ø§Ø®ØªØ± Ø§Ù„ÙŠÙˆÙ…:", list(WEEKLY_SCHEDULE.keys()))

    if file_tab1 and st.button("ğŸš€ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø°ÙƒØ±Ø©", key="btn1"):
        if not api_key: st.error("Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯!"); st.stop()
        
        with st.spinner(f'Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¯Ø±ÙˆØ³ ÙˆÙ…Ø·Ø§Ø¨Ù‚ØªÙ‡Ø§ Ù…Ø¹ ØªÙˆÙ‚ÙŠØª ÙŠÙˆÙ… {day_selected}...'):
            text = extract_text_from_docx(file_tab1)
            data = analyze_with_cerebras(text, api_key, model_choice, mode="journal")
            
            if "error" not in data:
                doc = create_daily_journal_doc(day_selected, data)
                bio = io.BytesIO()
                doc.save(bio)
                
                st.success("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! ØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")
                st.download_button(
                    label=f"ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ø°ÙƒØ±Ø© {day_selected} (Word)",
                    data=bio.getvalue(),
                    file_name=f"Journal_{day_selected}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )
            else:
                st.error(f"Ø®Ø·Ø£: {data['error']}")

# ==========================================
# Tab 2: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† (Ø§Ù„Ù…Ø¬Ø§Ù„/Ø§Ù„Ù…Ù‚Ø·Ø¹)
# ==========================================
with tab2:
    st.header("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ±Ø¨ÙˆÙŠØ© (Excel/JSON)")
    st.markdown("Ø§Ø³ØªØ®Ø±Ø§Ø¬: **Ø§Ù„Ù…Ø¬Ø§Ù„/Ø§Ù„Ù…Ù‚Ø·Ø¹ØŒ Ø§Ù„Ù†Ø´Ø§Ø·ØŒ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ØŒ Ø§Ù„ÙƒÙØ§Ø¡Ø©** ÙÙŠ Ø¬Ø¯ÙˆÙ„ Ù…Ù†Ø¸Ù….")
    
    file_tab2 = st.file_uploader("ğŸ“‚ Ù…Ù„Ù Ø§Ù„Ù…Ø°ÙƒØ±Ø§Øª (.docx)", type=["docx"], key="f2")
    
    if file_tab2 and st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", key="btn2"):
        if not api_key: st.error("Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯!"); st.stop()
        
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ù‡ÙŠÙƒÙ„Ø©...'):
            text = extract_text_from_docx(file_tab2)
            # ÙˆØ¶Ø¹ 'structure' Ù‡Ù†Ø§ Ù„ØªÙØ¹ÙŠÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆØ§Ù„Ù…Ø¬Ø§Ù„Ø§Øª
            result = analyze_with_cerebras(text, api_key, model_choice, mode="structure")
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© JSON
            final_data = []
            if isinstance(result, dict):
                for val in result.values():
                    if isinstance(val, list): final_data = val; break
                if not final_data and "error" not in result: final_data = [result]
            elif isinstance(result, list): final_data = result
            
            if final_data:
                df = pd.DataFrame(final_data)
                
                # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                cols = ["Ø§Ù„Ù…Ø¬Ø§Ù„_Ø£Ùˆ_Ø§Ù„Ù…Ù‚Ø·Ø¹", "Ø§Ù„Ù†Ø´Ø§Ø·", "Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹", "Ø§Ù„ÙƒÙØ§Ø¡Ø©_Ø§Ù„Ø®ØªØ§Ù…ÙŠØ©", "Ø§Ù„Ù…Ø¤Ø´Ø±"]
                df = df[[c for c in cols if c in df.columns] + [c for c in df.columns if c not in cols]]
                
                st.success(f"ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(df)} Ø¯Ø±Ø³Ø§Ù‹.")
                
                # Ø¬Ø¯ÙˆÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
                st.subheader("ğŸ“ Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                edited_df = st.data_editor(df, use_container_width=True, num_rows="dynamic")
                
                # ØªØ­Ù…ÙŠÙ„
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                    edited_df.to_excel(writer, index=False, sheet_name='Data')
                
                c1, c2 = st.columns(2)
                c1.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Excel", buffer.getvalue(), "lessons_structured.xlsx")
                c2.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ JSON", json.dumps(final_data, ensure_ascii=False), "data.json")
                
            else:
                st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‡ÙŠÙƒÙ„Ø© Ø£Ùˆ Ø­Ø¯Ø« Ø®Ø·Ø£.")
