
import streamlit as st
import requests
import json
import time
import sqlite3
import pandas as pd
import plotly.express as px
import re
from pydantic import BaseModel, Field, ValidationError
from typing import List, Optional, Dict, Any, Union

# ==========================================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…
# ==========================================
st.set_page_config(
    page_title="CineMate Pro - Ø§Ù„Ù†Ø§Ù‚Ø¯ Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

def apply_theme(theme):
    """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø³Ù…Ø§Øª (Themes) ÙˆØªØ®ØµÙŠØµ CSS"""
    if theme == "Ø¯Ø§ÙƒÙ†":
        bg_color = "#0e1117"
        text_color = "#fafafa"
        card_bg = "#262730"
        border_color = "#3b3b3b"
    else:
        bg_color = "#ffffff"
        text_color = "#31333F"
        card_bg = "#f0f2f6"
        border_color = "#cccccc"
    
    st.markdown(f"""
    <style>
        .main {{direction: rtl; text-align: right; background-color: {bg_color}; color: {text_color};}}
        .stTextInput > div > div > input {{text-align: right;}}
        .stTextArea > div > div > textarea {{text-align: right;}}
        h1, h2, h3, h4, p, span, div {{font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;}}
        .metric-card {{
            background-color: {card_bg}; 
            padding: 15px; 
            border-radius: 10px; 
            border: 1px solid {border_color}; 
            text-align: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }}
        .stTabs [data-baseweb="tab-list"] {{ justify-content: flex-end; }}
        .stTabs [data-baseweb="tab"] {{ font-weight: bold; }}
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Pydantic Models)
# ==========================================
class MovieInfo(BaseModel):
    arabic_title: str = Field(..., description="Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙÙŠÙ„Ù… Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    original_title: str = Field(..., description="Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø£ØµÙ„ÙŠ")
    year: Union[int, str] = Field(..., description="Ø³Ù†Ø© Ø§Ù„Ø¥ØµØ¯Ø§Ø±")
    director: str = Field(..., description="Ø§Ø³Ù… Ø§Ù„Ù…Ø®Ø±Ø¬")
    duration: str = Field(..., description="Ø§Ù„Ù…Ø¯Ø©")
    genre: List[str] = Field(..., description="Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    type: str = Field("ÙÙŠÙ„Ù…", description="ÙÙŠÙ„Ù… Ø£Ùˆ Ù…Ø³Ù„Ø³Ù„")

class TechnicalAnalysis(BaseModel):
    screenplay: str = Field(..., description="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ÙˆØ§Ù„Ø­Ø¨ÙƒØ©")
    acting: str = Field(..., description="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªÙ…Ø«ÙŠÙ„ÙŠ")
    visuals: str = Field(..., description="Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ ÙˆØ§Ù„Ø¨ØµØ±ÙŠØ§Øª")
    music: str = Field(..., description="Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰ ÙˆØ§Ù„ØµÙˆØª")
    symbolism: str = Field(..., description="Ø§Ù„Ø±Ù…Ø²ÙŠØ© ÙˆØ§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø®ÙÙŠØ©")

class Recommendation(BaseModel):
    score: float = Field(..., description="Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ù…Ù† 10")
    pros: List[str] = Field(..., description="Ø£Ø¨Ø±Ø² 3 Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª")
    cons: List[str] = Field(..., description="Ø£Ø¨Ø±Ø² 3 Ø³Ù„Ø¨ÙŠØ§Øª")
    similar_movies: List[str] = Field(..., description="3 Ø£Ø¹Ù…Ø§Ù„ Ù…Ø´Ø§Ø¨Ù‡Ø©")
    streaming_on: List[str] = Field(..., description="Ù…Ù†ØµØ§Øª Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©")
    final_verdict: str = Field(..., description="Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø®ØªØµØ±")

class FullMovieReport(BaseModel):
    info: MovieInfo
    analysis: TechnicalAnalysis
    recommendation: Recommendation

class ComparisonData(BaseModel):
    better_plot: str
    better_acting: str
    better_visuals: str
    better_music: str
    overall_winner: str
    verdict: str

class ComparisonResult(BaseModel):
    movies: List[FullMovieReport]
    comparison: ComparisonData

# ==========================================
# 3. Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (SQLite)
# ==========================================
DB_FILE = 'cinemate_v2.db'

def init_db():
    try:
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        c.execute('''CREATE TABLE IF NOT EXISTS reports
                     (id INTEGER PRIMARY KEY AUTOINCREMENT,
                      title TEXT,
                      arabic_title TEXT,
                      director TEXT,
                      genres TEXT,
                      score REAL,
                      year INTEGER,
                      type TEXT,
                      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')
        conn.commit()
    except sqlite3.Error as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
    finally:
        if 'conn' in locals(): conn.close()

def save_report_to_db(report: FullMovieReport):
    try:
        conn = sqlite3.connect(DB_FILE)
        c = conn.cursor()
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø³Ù†Ø© Ø¥Ù„Ù‰ Ø±Ù‚Ù… Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù†ØµØ§Ù‹ØŒ Ø£Ùˆ 0 Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„
        try:
            year_val = int(str(report.info.year).strip())
        except:
            year_val = 0

        c.execute('''INSERT INTO reports (title, arabic_title, director, genres, score, year, type)
                     VALUES (?, ?, ?, ?, ?, ?, ?)''',
                  (report.info.original_title,
                   report.info.arabic_title,
                   report.info.director,
                   json.dumps(report.info.genre, ensure_ascii=False),
                   report.recommendation.score,
                   year_val,
                   report.info.type))
        conn.commit()
    except sqlite3.Error as e:
        st.warning(f"Ù„Ù… ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ù„ÙŠ: {e}")
    finally:
        if 'conn' in locals(): conn.close()

def get_reports_from_db(limit=50):
    try:
        conn = sqlite3.connect(DB_FILE)
        df = pd.read_sql_query("SELECT * FROM reports ORDER BY created_at DESC LIMIT ?", conn, params=(limit,))
        conn.close()
        
        if not df.empty:
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¢Ù…Ù†Ø© Ù„ØªØ­ÙˆÙŠÙ„ JSON
            def safe_json_loads(x):
                try:
                    return json.loads(x) if isinstance(x, str) else []
                except:
                    return []
            
            df['genres'] = df['genres'].apply(safe_json_loads)
        return df
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø³Ø¬Ù„: {e}")
        return pd.DataFrame()

init_db()

# ==========================================
# 4. Ø¯ÙˆØ§Ù„ TMDB API
# ==========================================
@st.cache_data(ttl=3600, show_spinner=False)
def fetch_tmdb_data(api_key: str, query: str, is_tv: bool = False):
    """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† TMDB (ÙÙŠÙ„Ù… Ø£Ùˆ Ù…Ø³Ù„Ø³Ù„)"""
    if not api_key:
        return None
    
    base_url = "https://api.themoviedb.org/3"
    endpoint = "tv" if is_tv else "movie"
    search_url = f"{base_url}/search/{endpoint}"
    
    try:
        # 1. Ø§Ù„Ø¨Ø­Ø«
        params = {"api_key": api_key, "query": query, "language": "ar-SA"}
        response = requests.get(search_url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if not data.get('results'):
            return None
            
        item = data['results'][0]
        item_id = item['id']
        
        # 2. Ø§Ù„ØªÙØ§ØµÙŠÙ„ (Credits & Videos)
        details_params = {"api_key": api_key, "append_to_response": "credits,videos,recommendations"}
        details_url = f"{base_url}/{endpoint}/{item_id}"
        
        details_resp = requests.get(details_url, params=details_params, timeout=10)
        details_resp.raise_for_status()
        details = details_resp.json()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        cast = [p['name'] for p in details.get('credits', {}).get('cast', [])[:5]]
        
        director = "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
        if not is_tv:
            crew = details.get('credits', {}).get('crew', [])
            director = next((c['name'] for c in crew if c['job'] == 'Director'), "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
        else:
            created_by = details.get('created_by', [])
            if created_by:
                director = created_by[0]['name']

        trailer_key = None
        for vid in details.get('videos', {}).get('results', []):
            if vid['site'] == 'YouTube' and vid['type'] == 'Trailer':
                trailer_key = vid['key']
                break
        
        similar = [s['title'] if not is_tv else s['name'] for s in details.get('recommendations', {}).get('results', [])[:3]]

        return {
            'poster': f"https://image.tmdb.org/t/p/w500{item.get('poster_path')}" if item.get('poster_path') else None,
            'backdrop': f"https://image.tmdb.org/t/p/w1280{item.get('backdrop_path')}" if item.get('backdrop_path') else None,
            'rating': item.get('vote_average', 0),
            'overview': item.get('overview', ''),
            'cast': cast,
            'director': director,
            'trailer_key': trailer_key,
            'similar_tmdb': similar,
            'year': (item.get('release_date') or item.get('first_air_date') or "N/A")[:4]
        }
        
    except requests.exceptions.RequestException as e:
        # Ù„Ø§ Ù†ÙˆÙ‚Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø°Ø§ ÙØ´Ù„ TMDBØŒ ÙÙ‚Ø· Ù†Ø³Ø¬Ù„ ØªØ­Ø°ÙŠØ±Ø§Ù‹
        print(f"TMDB Error: {e}") 
        return None

# ==========================================
# 5. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (Cerebras)
# ==========================================
def extract_json_from_text(text: str) -> Optional[dict]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØ§Ø¦Ù† JSON ØµØ§Ù„Ø­ Ù…Ù† Ù†Øµ Ù‚Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ø§Ù… Ø¥Ø¶Ø§ÙÙŠ"""
    try:
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ù…Ø¨Ø§Ø´Ø±Ø©
        return json.loads(text)
    except json.JSONDecodeError:
        pass
    
    # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…Ø· JSON Ø¨ÙŠÙ† Ø£Ù‚ÙˆØ§Ø³ {}
    # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø£ÙˆÙ„ { ÙˆØ¢Ø®Ø± }
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group())
        except json.JSONDecodeError:
            pass
            
    return None

def analyze_media(api_key: str, queries: List[str], content_type: str = "ÙÙŠÙ„Ù…", comparison: bool = False) -> Union[FullMovieReport, ComparisonResult, None]:
    """Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Cerebras API Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Llama 3.1 70B Ù‡Ùˆ Ø§Ù„Ø´Ø§Ø¦Ø¹ Ø­Ø§Ù„ÙŠØ§Ù‹ Ø¹Ù„Ù‰ Cerebras)
    MODEL_NAME = "llama3.1-70b" 
    API_URL = "https://api.cerebras.ai/v1/chat/completions"
    
    media_str = " Ùˆ ".join(queries)
    
    # Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª (Prompt)
    if comparison:
        schema = json.dumps(ComparisonResult.model_json_schema(), indent=2, ensure_ascii=False)
        system_prompt = f"""
        You are a legendary Arab Film Critic. Compare these {content_type}s: {media_str}.
        Output STRICT JSON matching this schema:
        {schema}
        Language: Arabic. Do not add markdown backticks.
        """
    else:
        schema = json.dumps(FullMovieReport.model_json_schema(), indent=2, ensure_ascii=False)
        system_prompt = f"""
        You are a legendary Arab Film Critic. Analyze the {content_type}: "{media_str}".
        Output STRICT JSON matching this schema:
        {schema}
        Language: Arabic. Do not add markdown backticks.
        """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"Analyze: {media_str}"}
    ]

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 4000,
        "response_format": {"type": "json_object"}
    }

    try:
        response = requests.post(API_URL, headers=headers, json=payload, timeout=45)
        response.raise_for_status()
        result = response.json()
        content = result['choices'][0]['message']['content']
        
        parsed_data = extract_json_from_text(content)
        if not parsed_data:
            raise ValueError("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON ØµØ§Ù„Ø­ Ù…Ù† Ø§Ù„Ø±Ø¯.")

        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Pydantic
        if comparison:
            return ComparisonResult(**parsed_data)
        else:
            return FullMovieReport(**parsed_data)

    except requests.exceptions.HTTPError as http_err:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ API: {http_err.response.status_code} - {http_err.response.text}")
    except ValidationError as val_err:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‡ÙŠÙƒÙ„ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªÙ„Ù…Ø©: {val_err}")
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
    
    return None

# ==========================================
# 6. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Main)
# ==========================================
def main():
    # --- Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ ---
    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/2503/2503508.png", width=80)
        st.title("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        
        # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
        cerebras_key = st.session_state.get('cerebras_key', '')
        tmdb_key = st.session_state.get('tmdb_key', '')
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ù† secrets Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
        if not cerebras_key and "cerebras_key" in st.secrets:
            cerebras_key = st.secrets["cerebras_key"]
        
        if not tmdb_key and "tmdb_key" in st.secrets:
            tmdb_key = st.secrets["tmdb_key"]

        # Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
        new_c_key = st.text_input("Cerebras API Key", value=cerebras_key, type="password")
        new_t_key = st.text_input("TMDB API Key (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)", value=tmdb_key, type="password")
        
        if new_c_key: st.session_state['cerebras_key'] = new_c_key
        if new_t_key: st.session_state['tmdb_key'] = new_t_key
        
        st.divider()
        
        theme = st.selectbox("Ø§Ù„Ù…Ø¸Ù‡Ø±", ["ÙØ§ØªØ­", "Ø¯Ø§ÙƒÙ†"])
        apply_theme(theme)
        
        content_type = st.radio("Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰", ["ÙÙŠÙ„Ù…", "Ù…Ø³Ù„Ø³Ù„"], horizontal=True)
        comparison_mode = st.checkbox("ÙˆØ¶Ø¹ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Ø£ÙƒØ«Ø± Ù…Ù† Ø¹Ù…Ù„)")
        
        num_movies = 1
        if comparison_mode:
            num_movies = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø§Ù„", min_value=2, max_value=4, value=2)

        st.divider()
        st.subheader("Ø³Ø¬Ù„ Ø§Ù„Ø¨Ø­Ø«")
        history_df = get_reports_from_db(5)
        if not history_df.empty:
            for _, row in history_df.iterrows():
                st.caption(f"ğŸ¬ {row['arabic_title']} ({row['score']}/10)")
        else:
            st.caption("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ø¨Ø¹Ø¯.")

    # --- Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ---
    st.title("ğŸ¬ CineMate Pro")
    st.markdown("#### Ù…Ù†ØµØ© Ø§Ù„Ù†Ù‚Ø¯ Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    
    if not st.session_state.get('cerebras_key'):
        st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ Cerebras API ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ø¨Ø¯Ø¡.")
        st.stop()

    # Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
    movies_list = []
    cols = st.columns(num_movies)
    for i, col in enumerate(cols):
        with col:
            placeholder = "Ù…Ø«Ø§Ù„: The Godfather" if i == 0 else "Ù…Ø«Ø§Ù„: Goodfellas"
            val = st.text_input(f"Ø§Ù„Ø¹Ù…Ù„ Ø±Ù‚Ù… {i+1}", key=f"movie_in_{i}", placeholder=placeholder)
            if val: movies_list.append(val)

    if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„", use_container_width=True):
        if len(movies_list) < num_movies:
            st.error(f"ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø£Ø³Ù…Ø§Ø¡ {num_movies} Ø£Ø¹Ù…Ø§Ù„.")
        else:
            main_placeholder = st.empty()
            with main_placeholder.container():
                st.info("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰... ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±.")
                progress = st.progress(0)
                
                # 1. Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª TMDB (ØªÙˆØ§Ø²ÙŠ ÙˆÙ‡Ù…ÙŠ Ø¹Ø¨Ø± Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ø³Ø±ÙŠØ¹)
                tmdb_results = []
                for idx, movie in enumerate(movies_list):
                    progress.progress((idx + 1) * 10, text=f"Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Metadata Ù„Ù€: {movie}")
                    t_data = fetch_tmdb_data(st.session_state.get('tmdb_key'), movie, is_tv=(content_type=="Ù…Ø³Ù„Ø³Ù„"))
                    tmdb_results.append(t_data)
                
                # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
                progress.progress(50, text="Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‚Ø¯ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚ (Cerebras AI)...")
                analysis_result = analyze_media(
                    st.session_state['cerebras_key'], 
                    movies_list, 
                    content_type=content_type, 
                    comparison=comparison_mode
                )
                
                progress.progress(100, text="Ø§ÙƒØªÙ…Ù„!")
                time.sleep(0.5)
                progress.empty()
                main_placeholder.empty()

                if analysis_result:
                    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙØ±Ø¯ÙŠØ© Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø¹Ø±Ø¶
                    reports = []
                    comp_data = None
                    
                    if comparison_mode and isinstance(analysis_result, ComparisonResult):
                        reports = analysis_result.movies
                        comp_data = analysis_result.comparison
                    elif isinstance(analysis_result, FullMovieReport):
                        reports = [analysis_result]

                    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                    for r in reports:
                        save_report_to_db(r)

                    # --- Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ---
                    
                    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ù‚Ø§Ø±Ù†Ø©ØŒ Ø¹Ø±Ø¶ Ù‚Ø³Ù… Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø£ÙˆÙ„Ø§Ù‹
                    if comparison_mode and comp_data:
                        st.header("âš–ï¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
                        w_col1, w_col2 = st.columns([1, 2])
                        with w_col1:
                            st.metric("ğŸ† Ø§Ù„ÙØ§Ø¦Ø² Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ", comp_data.overall_winner)
                        with w_col2:
                            st.info(f"**Ø§Ù„Ø­ÙƒÙ…:** {comp_data.verdict}")
                        
                        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
                        comp_df = pd.DataFrame({
                            "Ø§Ù„Ù…Ø¹ÙŠØ§Ø±": ["Ø§Ù„Ù‚ØµØ©", "Ø§Ù„ØªÙ…Ø«ÙŠÙ„", "Ø§Ù„Ø¨ØµØ±ÙŠØ§Øª", "Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰"],
                            "Ø§Ù„Ø£ÙØ¶Ù„": [comp_data.better_plot, comp_data.better_acting, comp_data.better_visuals, comp_data.better_music]
                        })
                        st.table(comp_df)
                        
                        # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª
                        scores = {r.info.arabic_title: r.recommendation.score for r in reports}
                        fig = px.bar(
                            x=list(scores.keys()), 
                            y=list(scores.values()), 
                            labels={'x':'Ø§Ù„Ø¹Ù…Ù„', 'y':'Ø§Ù„ØªÙ‚ÙŠÙŠÙ…'},
                            title="Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…Ø§Øª",
                            color=list(scores.values()),
                            color_continuous_scale='Viridis',
                            range_y=[0, 10]
                        )
                        st.plotly_chart(fig, use_container_width=True)
                        st.divider()

                    # Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ ÙƒÙ„ ÙÙŠÙ„Ù…
                    for i, report in enumerate(reports):
                        t_data = tmdb_results[i] if i < len(tmdb_results) else None
                        
                        with st.container():
                            # Ø±Ø£Ø³ Ø§Ù„Ø¨Ø·Ø§Ù‚Ø©
                            col_img, col_txt = st.columns([1, 3])
                            with col_img:
                                if t_data and t_data.get('poster'):
                                    st.image(t_data['poster'], use_container_width=True)
                                else:
                                    st.markdown("ğŸ“· ØµÙˆØ±Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")
                            
                            with col_txt:
                                st.subheader(f"{report.info.arabic_title} ({report.info.year})")
                                st.caption(f"{report.info.original_title} | {report.info.director}")
                                
                                m1, m2, m3 = st.columns(3)
                                m1.metric("Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‚Ø¯ÙŠ", f"{report.recommendation.score}/10")
                                m2.metric("Ø§Ù„Ù†ÙˆØ¹", ", ".join(report.info.genre[:2]))
                                if t_data:
                                    m3.metric("ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬Ù…Ù‡ÙˆØ± (TMDB)", f"{t_data.get('rating')}/10")
                                
                                if t_data and t_data.get('trailer_key'):
                                    with st.expander("ğŸ¥ Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ø§Ù„ØªØ´ÙˆÙŠÙ‚ÙŠ"):
                                        st.video(f"https://www.youtube.com/watch?v={t_data['trailer_key']}")

                            # ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„ØªÙØ§ØµÙŠÙ„
                            tab1, tab2, tab3 = st.tabs(["Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ", "Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª ÙˆØ§Ù„Ø³Ù„Ø¨ÙŠØ§Øª", "Ø§Ù„ØªÙˆØµÙŠØ§Øª"])
                            
                            with tab1:
                                st.markdown(f"**Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ:** {report.analysis.screenplay}")
                                st.markdown(f"**Ø§Ù„ØªÙ…Ø«ÙŠÙ„:** {report.analysis.acting}")
                                st.markdown(f"**Ø§Ù„Ø¨ØµØ±ÙŠØ§Øª:** {report.analysis.visuals}")
                                st.markdown(f"**Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰:** {report.analysis.music}")
                                st.markdown(f"--- \n **ğŸ’¡ Ø§Ù„Ø±Ù…Ø²ÙŠØ©:** {report.analysis.symbolism}")

                            with tab2:
                                c1, c2 = st.columns(2)
                                with c1:
                                    st.success("âœ… **Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©**")
                                    for p in report.recommendation.pros: st.write(f"- {p}")
                                with c2:
                                    st.error("âŒ **Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù**")
                                    for c in report.recommendation.cons: st.write(f"- {c}")
                                st.markdown(f"**ğŸ“ Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:** {report.recommendation.final_verdict}")

                            with tab3:
                                st.write("**ğŸ“º Ù…Ù†ØµØ§Øª Ù…Ù‚ØªØ±Ø­Ø©:** " + "ØŒ ".join(report.recommendation.streaming_on))
                                st.write("**ğŸ”— Ø£Ø¹Ù…Ø§Ù„ Ù…Ø´Ø§Ø¨Ù‡Ø© (AI):** " + "ØŒ ".join(report.recommendation.similar_movies))
                                if t_data and t_data.get('similar_tmdb'):
                                    st.write("**ğŸ”— Ø£Ø¹Ù…Ø§Ù„ Ù…Ø´Ø§Ø¨Ù‡Ø© (TMDB):** " + "ØŒ ".join(t_data['similar_tmdb']))

                        st.divider()

if __name__ == "__main__":
    main()
