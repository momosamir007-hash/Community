import streamlit as st
import requests
import json

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="AI Debugger (Cerebras + GLM-5)", page_icon="ğŸ§ª")

# ØªØ®ØµÙŠØµ CSS
st.markdown("""
<style>
    .stChatMessage { direction: rtl; text-align: right; }
    .stTextInput > div > div > input { direction: rtl; text-align: right; }
    .stSelectbox > div > div > div { direction: rtl; }
    .stExpander { direction: rtl; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ§ª ÙØ­Øµ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª (Cerebras + GLM-5)")

# --- 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙˆØ§Ù„Ø±ÙˆØ§Ø¨Ø· ---
with st.sidebar:
    st.header("ğŸ”‘ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙØ§ØªÙŠØ­")
    
    # 1. Ù…ÙØªØ§Ø­ Cerebras
    try:
        cerebras_key = st.secrets["CEREBRAS_API_KEY"]
    except:
        cerebras_key = st.text_input("Ù…ÙØªØ§Ø­ Cerebras API:", type="password")

    # 2. Ù…ÙØªØ§Ø­ Zed.ai / GLM
    try:
        zed_key = st.secrets["ZED_API_KEY"]
    except:
        zed_key = st.text_input("Ù…ÙØªØ§Ø­ Zed.ai API:", type="password")

    st.markdown("---")
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    with st.expander("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø±ÙˆØ§Ø¨Ø· (Base URLs)"):
        # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ ÙƒÙ†Øª ØªØ³ØªØ®Ø¯Ù… chat.z.aiØŒ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø®ØªÙ„ÙØ§Ù‹ Ø¹Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø±Ø³Ù…ÙŠ
        # Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø±Ø³Ù…ÙŠ Ù‡Ùˆ: https://open.bigmodel.cn/api/paas/v4/chat/completions
        # Ø±Ø§Ø¨Ø· chat.z.ai Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ (Ø¬Ø±Ø¨ Ù‡Ø°Ø§ Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¹Ù…Ù„ Ø§Ù„Ø±Ø³Ù…ÙŠ): https://chat.z.ai/api/v1/chat/completions
        
        default_zed_url = st.text_input(
            "Ø±Ø§Ø¨Ø· Zed.ai / GLM:", 
            value="https://open.bigmodel.cn/api/paas/v4/chat/completions",
            help="Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¹Ù…Ù„ØŒ Ø¬Ø±Ø¨: https://chat.z.ai/api/v1/chat/completions"
        )
        
        cerebras_url = "https://api.cerebras.ai/v1/chat/completions"

# --- 3. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø­Ø³Ø¨ Ø§Ù„ØµÙˆØ±Ø©) ---
with st.sidebar:
    st.header("ğŸ¤– Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„")
    
    model_options = {
        "Cerebras": [
            "llama-3.3-70b",
            "llama3.1-8b",
            "qwen-3-32b"
        ],
        "Zed.ai (GLM)": [
            "glm-5",           # âœ… Ø§Ù„Ø¬Ø¯ÙŠØ¯ (Flagship)
            "glm-4.7",         # âœ… Ù…ÙˆØ¯ÙŠÙ„ Ù‚ÙˆÙŠ
            "glm-4.6",         # âœ… ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡
            "glm-4-plus",      # Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø§Ù„Ù‚ÙˆÙŠ
            "glm-4-air",       # Ø³Ø±ÙŠØ¹
            "glm-4-flash"      # Ø§Ù‚ØªØµØ§Ø¯ÙŠ
        ]
    }
    
    provider = st.selectbox("Ø§Ù„Ù…Ø²ÙˆØ¯:", list(model_options.keys()))
    
    # Ø®ÙŠØ§Ø± Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ø³Ù… Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ¯ÙˆÙŠØ§Ù‹ ÙÙŠ Ø­Ø§Ù„Ø© Ø¸Ù‡ÙˆØ± Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
    selected_model_dropdown = st.selectbox("Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„:", model_options[provider])
    use_manual = st.checkbox("ÙƒØªØ§Ø¨Ø© Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ¯ÙˆÙŠØ§Ù‹ØŸ")
    
    if use_manual:
        selected_model = st.text_input("Ø§ÙƒØªØ¨ Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ù…Ø«Ø§Ù„: glm-4.6v):", value=selected_model_dropdown)
    else:
        selected_model = selected_model_dropdown

    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- 4. Ø¯Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ù…ÙˆØ­Ø¯Ø© ---
def stream_chat_debug(messages, model, provider_name, c_key, z_key, c_url, z_url):
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    if provider_name == "Zed.ai (GLM)":
        url = z_url
        api_key = z_key
        if not api_key:
            yield "â›” **Ø®Ø·Ø£:** Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ Zed.ai."
            return
    else:
        url = c_url
        api_key = c_key
        if not api_key:
            yield "â›” **Ø®Ø·Ø£:** Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ Cerebras."
            return

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model,
        "messages": messages,
        "stream": True,
        "max_tokens": 1500 
    }
    
    try:
        response = requests.post(url, headers=headers, json=data, stream=True)
        
        if response.status_code != 200:
            try:
                err_json = response.json()
                err_msg = err_json.get('error', {}).get('message', response.text)
                yield f"â›” **ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ {provider_name}:**\nØ±Ù…Ø² Ø§Ù„Ø®Ø·Ø£: {response.status_code}\nØ§Ù„Ø±Ø³Ø§Ù„Ø©: {err_msg}"
            except:
                yield f"â›” **Ø®Ø·Ø£ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ:** {response.text}"
            return

        for line in response.iter_lines():
            if line:
                decoded = line.decode('utf-8').replace("data: ", "")
                if decoded.strip() == "[DONE]": break
                try:
                    chunk = json.loads(decoded)
                    content = chunk['choices'][0]['delta'].get('content', '')
                    if content: yield content
                except: continue
                
    except Exception as e:
        yield f"âŒ **Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ©:** {e}"

# --- 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_holder = st.empty()
        full_text = ""
        
        stream_gen = stream_chat_debug(
            st.session_state.messages, 
            selected_model, 
            provider,
            cerebras_key, 
            zed_key,
            cerebras_url,
            default_zed_url  # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„ØµØ­ÙŠØ­
        )
        
        for chunk in stream_gen:
            full_text += chunk
            response_holder.markdown(full_text + "â–Œ")
        
        response_holder.markdown(full_text)
        
        if "â›”" not in full_text and "âŒ" not in full_text:
            st.session_state.messages.append({"role": "assistant", "content": full_text})

