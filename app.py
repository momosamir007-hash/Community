import streamlit as st
from cerebras.cloud.sdk import Cerebras

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© (ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø£ÙˆÙ„ Ø³Ø·Ø±)
st.set_page_config(page_title="Cerebras Chat", page_icon="âš¡", layout="centered")

st.title("âš¡ Cerebras Fast Chat")
st.caption("Ù…Ø¯Ø¹ÙˆÙ… Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ù…ÙˆØ°Ø¬ Llama-3.1-70b ÙˆØ³Ø±Ø¹Ø© Cerebras")

# 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Sidebar) Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­
with st.sidebar:
    st.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    api_key = st.text_input("Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ Cerebras API:", type="password")
    st.markdown("[Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ Ù…Ø¬Ø§Ù†ÙŠ Ù…Ù† Ù‡Ù†Ø§](https://cloud.cerebras.ai/)")
    
    # Ø²Ø± Ù„Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    if st.button("Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ğŸ—‘ï¸"):
        st.session_state.messages = []
        st.rerun()

# 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ÙØªØ§Ø­ Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡
if not api_key:
    st.info("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ API Key ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©.")
    st.stop()

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ù…Ø¯Ø®Ù„
client = Cerebras(api_key=api_key)

# 4. Ø¥Ø¯Ø§Ø±Ø© Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Ù…Ø±Ø­Ø¨Ø§Ù‹! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ø³Ø±Ø¹Ø© Ø§Ù„ÙŠÙˆÙ…ØŸ"}]

# 5. Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙÙŠ Ø§Ù„Ø´Ø§Ø´Ø©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§..."):
    # Ø£. Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ø¨. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ ÙˆØ§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø±Ø¯ (Streaming)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            stream = client.chat.completions.create(
                model="llama3.1-70b",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ÙÙŠØ¯."}
                ] + [
                    {"role": m["role"], "content": m["content"]} 
                    for m in st.session_state.messages
                ],
                stream=True,
            )
            
            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø¯ ÙƒÙ„Ù…Ø© Ø¨ÙƒÙ„Ù…Ø©
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
        
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
            full_response = "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„."

    # Ø¬. Ø­ÙØ¸ Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    st.session_state.messages.append({"role": "assistant", "content": full_response})
