import streamlit as st
import requests
import json

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(
    page_title="Cerebras 6 Models",
    page_icon="âš¡",
    layout="centered"
)

# ØªØ®ØµÙŠØµ CSS Ù„Ø¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
st.markdown("""
<style>
    .stChatMessage { direction: rtl; text-align: right; }
    .stTextInput > div > div > input { direction: rtl; text-align: right; }
    p { text-align: right; }
</style>
""", unsafe_allow_html=True)

st.title("âš¡ Cerebras: Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ø³Ø¯Ø§Ø³ÙŠØ©")

# --- 2. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙØªØ§Ø­ (Secrets) ---
try:
    api_key = st.secrets["CEREBRAS_API_KEY"]
    st.sidebar.success("âœ… Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ØªØµÙ„ (Secrets)")
except (FileNotFoundError, KeyError):
    api_key = st.sidebar.text_input("Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ API:", type="password")

if not api_key:
    st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªÙˆÙÙŠØ± Ù…ÙØªØ§Ø­ API Ù„Ù„Ø¨Ø¯Ø¡.")
    st.stop()

# --- 3. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù€ 6) ---
with st.sidebar:
    st.header("ğŸ›ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    
    # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ø³ØªØ© Ø§Ù„ØªÙŠ Ø¸Ù‡Ø±Øª Ù„Ùƒ
    models_list = [
        "llama-3.3-70b",        # Ø§Ù„Ø£Ù‚ÙˆÙ‰ ÙˆØ§Ù„Ø£Ø­Ø¯Ø«
        "llama3.1-8b",          # Ø§Ù„Ø³Ø±ÙŠØ¹ ÙˆØ§Ù„Ø®ÙÙŠÙ
        "qwen-3-32b",           # Ù…Ù…ØªØ§Ø² ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©
        "gpt-oss-120b",         # Ù…ÙˆØ¯ÙŠÙ„ Ø¶Ø®Ù…
        "zai-glm-4.7",          # Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ®ØµØµ
        "qwen-3-235b-a22b-instruct-2507" # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Ù‚
    ]
    
    selected_model = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„:", models_list, index=0)
    
    st.info(f"Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠ: **{selected_model}**")
    
    system_prompt = st.text_area(
        "ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:",
        value="Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙˆÙ…ÙÙŠØ¯.",
        height=100
    )
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- 4. Ø¯Ø§Ù„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ (Streaming) ---
def stream_chat(messages, api_key, model, system_prompt):
    url = "https://api.cerebras.ai/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "model": model,
        "messages": [{"role": "system", "content": system_prompt}] + messages,
        "stream": True,
        "max_tokens": 2000,
        "temperature": 0.7
    }
    
    try:
        with requests.post(url, headers=headers, json=data, stream=True) as r:
            if r.status_code != 200:
                yield f"âš ï¸ Ø®Ø·Ø£: {r.text}"
                return
                
            for line in r.iter_lines():
                if line:
                    decoded = line.decode('utf-8').replace("data: ", "")
                    if decoded.strip() == "[DONE]": break
                    try:
                        chunk = json.loads(decoded)
                        content = chunk['choices'][0]['delta'].get('content', '')
                        if content: yield content
                    except: continue
    except Exception as e:
        yield f"âŒ Ø®Ø·Ø£: {e}"

# --- 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        response_placeholder = st.empty()
        full_response = ""
        for chunk in stream_chat(st.session_state.messages, api_key, selected_model, system_prompt):
            full_response += chunk
            response_placeholder.markdown(full_response + "â–Œ")
        response_placeholder.markdown(full_response)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})
